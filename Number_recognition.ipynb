{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda8644a",
   "metadata": {},
   "source": [
    "# Reconocimiento de números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e68ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time #para calcular tiempos\n",
    "import scipy.special #para la función sigmoide\n",
    "import matplotlib.pyplot as plt #para representar las gráficas\n",
    "#para asegurarnos de que las gráficas estan en este cuaderno y no una ventana externa\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a8a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicion de la clase \n",
    "class neuralNetwork:\n",
    "    #inicialización de la red neuronal\n",
    "    def __init__(self,nodosent,nodosocu,nodossal,aprendizaje):\n",
    "        #establecemos el numero de nodos para la capa de entrada, la oculta y la de salida (e,o,s respectivamente)\n",
    "        self.enodos=nodosent\n",
    "        self.onodos=nodosocu\n",
    "        self.snodos=nodossal\n",
    "        \n",
    "        #matrices de peso peo (peso entrada-coulta), pos (peso oculta-salida)\n",
    "        self.weo=numpy.random.normal(0.0, pow(self.onodos, -0.5),(self.onodos, self.enodos))\n",
    "        self.wos = numpy.random.normal(0.0, pow(self.snodos, -0.5),(self.snodos, self.onodos))\n",
    "\n",
    "        #tasa de aprendizaje\n",
    "        self.ta=aprendizaje\n",
    "        \n",
    "        #función de activación (sigmoide)\n",
    "        self.activacion_funcion= lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    #función entrenamiento\n",
    "    def entrena(self, lista_entrada, lista_objetivo):\n",
    "        #convertimos las entradas y los objetivos en un array de 2 dimensiones\n",
    "        entradas = numpy.array(lista_entrada, ndmin=2).T\n",
    "        objetivos = numpy.array(lista_objetivo, ndmin=2).T\n",
    "        \n",
    "        #calculamos las entradas a la capa oculta\n",
    "        entrada_oculta = numpy.dot(self.weo, entradas)\n",
    "        #calculamos las salidas de la capa oculta\n",
    "        salida_oculta=self.activacion_funcion(entrada_oculta)\n",
    "        #calculamos las entradas de la capa final\n",
    "        entrada_final = numpy.dot(self.wos, salida_oculta)\n",
    "        #calculamos la salida de la capa final\n",
    "        salida_final = self.activacion_funcion(entrada_final)\n",
    "\n",
    "        #calculo de errores\n",
    "        errores_salida = objetivos - salida_final\n",
    "\n",
    "        #el error oculto es errores_salida, dividido entre los pesos y recombinado con los nodos ocultos (ver en la teoría capítulo 1)\n",
    "        errores_oculta=numpy.dot(self.wos.T, errores_salida)\n",
    "        \n",
    "        #actualización de los pesos entre la capa oculta y la final\n",
    "        self.wos += self.ta * numpy.dot((errores_salida *salida_final * (1.0 -salida_final)),numpy.transpose(salida_oculta))\n",
    "        \n",
    "        #actualizacion de los pesos entre la capa de entrada y la oculta\n",
    "        self.weo += self.ta * numpy.dot((errores_oculta *salida_oculta * (1.0 - salida_oculta)), numpy.transpose(entradas))\n",
    "\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    #probamos la red neuronal\n",
    "    def prob(self,lista_entrada):\n",
    "        #convertimos las entradas en un array dimensión 2\n",
    "        entradas = numpy.array(lista_entrada, ndmin=2).T\n",
    "        \n",
    "        #calculamos la entrada de la capa oculta\n",
    "        entrada_oculta = numpy.dot(self.weo, entradas)\n",
    "        \n",
    "        #calculamos la salida de la capa oculta\n",
    "        salida_oculta = self.activacion_funcion(entrada_oculta)\n",
    "\n",
    "        #calcula la entrada en la capa final\n",
    "        entrada_final= numpy.dot(self.wos, salida_oculta)\n",
    "        #calcula la salida de la capa final\n",
    "        salida_final = self.activacion_funcion(entrada_final)\n",
    "\n",
    "        return salida_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1d4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numero de nodos en cada capa\n",
    "nodosent=784 #ya que las imágenes son de 28*28 píxeles\n",
    "nodosocu = 200\n",
    "nodossal = 10 #por tener 10 opciones de números\n",
    "\n",
    "#tasa aprendizaje\n",
    "aprendizaje=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede02e3",
   "metadata": {},
   "source": [
    "## Red neuronal con 60000 datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f2cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.34344482421875\n"
     ]
    }
   ],
   "source": [
    "start1=time.time() #inicializamos el tiempo\n",
    "# ejemplo de red neuronal\n",
    "n = neuralNetwork(nodosent,nodosocu,nodossal,aprendizaje)\n",
    "\n",
    "#cargamos el archivo de los datos de entrenamiento\n",
    "archivo_datos=open(\"mnist_train.csv\",\"r\")\n",
    "lista_datos=archivo_datos.readlines()\n",
    "archivo_datos.close()\n",
    "\n",
    "\n",
    "for record in lista_datos:\n",
    "    #separamos los datos de las listas por las comas\n",
    "    valores=record.split(',')\n",
    "    #ponemos los valores en la escala que nos interesa\n",
    "    #los datos comienzan en la posición uno ya que la 0 es la respuesta correcta del número del cual se trata\n",
    "    entrada_escalada = (numpy.asfarray(valores[1:]) / 255.0 * 0.99)+0.01\n",
    "    #creamos los objetivos salida (todos los valores 0,01 menos el deseado que es 0,99)\n",
    "    objetivos = numpy.zeros(nodossal) + 0.01\n",
    "    objetivos[int(valores[0])]=0.99\n",
    "    n.entrena(entrada_escalada,objetivos)\n",
    "    pass\n",
    "tiempo1=time.time()-start1\n",
    "print(tiempo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea95d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vamos a poner a prueba la red neuronal\n",
    "archivo_test = open(\"mnist_test.csv\", 'r')\n",
    "lista_test = archivo_test.readlines()\n",
    "archivo_test.close()\n",
    "\n",
    "#creamos una lista vacía para llevar el tanteo de los aciertos y fallos\n",
    "tanteo=[]\n",
    "\n",
    "for record in lista_test:\n",
    "    #separamos en la lista por comas\n",
    "    valores = record.split(',')\n",
    "    #tomamos la etiqueta correcta\n",
    "    etiqueta_correcta = int(valores[0])\n",
    "    #escalamos las entradas\n",
    "    entradas = (numpy.asfarray(valores[1:]) / 255.0 * 0.99)+0.01\n",
    "    \n",
    "    salidas = n.prob(entradas)\n",
    "    #el mayor indice de salida corresponde a la etiqueta\n",
    "    etiqueta=numpy.argmax(salidas)\n",
    "    #añadimos a la lista tanteo un 1 si ha acertado y un 0 si no\n",
    "    if (etiqueta == etiqueta_correcta):\n",
    "        tanteo.append(1)\n",
    "    else:\n",
    "        tanteo.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f185b",
   "metadata": {},
   "source": [
    "### Rendimiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a970186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rendimiento=  0.959\n"
     ]
    }
   ],
   "source": [
    "tanteo_array=numpy.asarray(tanteo)\n",
    "print(\"rendimiento= \",tanteo_array.sum()/tanteo_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a073ef29",
   "metadata": {},
   "source": [
    "## Red neuronal con 30000 datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7851bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de espera  80.07762575149536\n"
     ]
    }
   ],
   "source": [
    "start2=time.time()\n",
    "#red neuronal con menor entrenamiento\n",
    "n2 = neuralNetwork(nodosent,nodosocu,nodossal,aprendizaje)\n",
    "\n",
    "#cargamos el archivo de los datos de entrenamiento\n",
    "archivo_datos2=open(\"mnist_train2.csv\",\"r\")\n",
    "lista_datos2=archivo_datos2.readlines()\n",
    "archivo_datos2.close()\n",
    "\n",
    "\n",
    "for record in lista_datos2:\n",
    "    #separamos los datos de las listas por las comas\n",
    "    valores2=record.split(',')\n",
    "    #ponemos los valores en la escala que nos interesa\n",
    "    #los datos comienzan en la posición uno ya que la 0 es la respuesta correcta del número del cual se trata\n",
    "    entrada_escalada2 = (numpy.asfarray(valores2[1:]) / 255.0 * 0.99)+0.01\n",
    "    #creamos los objetivos salida (todos los valores 0,01 menos el deseado que es 0,99)\n",
    "    objetivos2 = numpy.zeros(nodossal) + 0.01\n",
    "    objetivos2[int(valores2[0])]=0.99\n",
    "    n2.entrena(entrada_escalada2,objetivos2)\n",
    "    pass\n",
    "tiempo2=time.time()-start2\n",
    "print(\"Tiempo de espera \",tiempo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea16a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vamos a poner a prueba la red neuronal\n",
    "archivo_test = open(\"mnist_test.csv\", 'r')\n",
    "lista_test = archivo_test.readlines()\n",
    "archivo_test.close()\n",
    "\n",
    "#creamos una lista vacía para llevar el tanteo de los aciertos y fallos\n",
    "tanteo2=[]\n",
    "\n",
    "for record in lista_test:\n",
    "    #separamos en la lista por comas\n",
    "    valores = record.split(',')\n",
    "    #tomamos la etiqueta correcta\n",
    "    etiqueta_correcta = int(valores[0])\n",
    "    #escalamos las entradas\n",
    "    entradas = (numpy.asfarray(valores[1:]) / 255.0 * 0.99)+0.01\n",
    "    \n",
    "    salidas = n2.prob(entradas)\n",
    "    #el mayor indice de salida corresponde a la etiqueta\n",
    "    etiqueta2=numpy.argmax(salidas)\n",
    "    #añadimos a la lista tanteo un 1 si ha acertado y un 0 si no\n",
    "    if (etiqueta2 == etiqueta_correcta):\n",
    "        tanteo2.append(1)\n",
    "    else:\n",
    "        tanteo2.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18453367",
   "metadata": {},
   "source": [
    "### Rendimiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0614e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rendimiento=  0.9461\n"
     ]
    }
   ],
   "source": [
    "tanteo2_array=numpy.asarray(tanteo2)\n",
    "print(\"rendimiento= \",tanteo2_array.sum()/tanteo2_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b6a36",
   "metadata": {},
   "source": [
    "## Red neuronal con 25000 datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23343824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.21252346038818\n"
     ]
    }
   ],
   "source": [
    "start3=time.time()\n",
    "#red neuronal con aún menor entrenamiento\n",
    "n3 = neuralNetwork(nodosent,nodosocu,nodossal,aprendizaje)\n",
    "\n",
    "#cargamos el archivo de los datos de entrenamiento\n",
    "archivo_datos3=open(\"mnist_train3.csv\",\"r\")\n",
    "lista_datos3=archivo_datos3.readlines()\n",
    "archivo_datos3.close()\n",
    "\n",
    "\n",
    "for record in lista_datos3:\n",
    "    #separamos los datos de las listas por las comas\n",
    "    valores3=record.split(',')\n",
    "    #ponemos los valores en la escala que nos interesa\n",
    "    #los datos comienzan en la posición uno ya que la 0 es la respuesta correcta del número del cual se trata\n",
    "    entrada_escalada3 = (numpy.asfarray(valores3[1:]) / 255.0 * 0.99)+0.01\n",
    "    #creamos los objetivos salida (todos los valores 0,01 menos el deseado que es 0,99)\n",
    "    objetivos3 = numpy.zeros(nodossal) + 0.01\n",
    "    objetivos3[int(valores2[0])]=0.99\n",
    "    n3.entrena(entrada_escalada3,objetivos3)\n",
    "    pass\n",
    "tiempo3=time.time()-start3\n",
    "print(tiempo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03331f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vamos a poner a prueba la red neuronal 25000 valores entrenamiento\n",
    "archivo_test = open(\"mnist_test.csv\", 'r')\n",
    "lista_test = archivo_test.readlines()\n",
    "archivo_test.close()\n",
    "\n",
    "#creamos una lista vacía para llevar el tanteo de los aciertos y fallos\n",
    "tanteo3=[]\n",
    "\n",
    "for record in lista_test:\n",
    "    #separamos en la lista por comas\n",
    "    valores = record.split(',')\n",
    "    #tomamos la etiqueta correcta\n",
    "    etiqueta_correcta = int(valores[0])\n",
    "    #escalamos las entradas\n",
    "    entradas = (numpy.asfarray(valores[1:]) / 255.0 * 0.99)+0.01\n",
    "    \n",
    "    salidas = n3.prob(entradas)\n",
    "    #el mayor indice de salida corresponde a la etiqueta\n",
    "    etiqueta3=numpy.argmax(salidas)\n",
    "    #añadimos a la lista tanteo un 1 si ha acertado y un 0 si no\n",
    "    if (etiqueta3 == etiqueta_correcta):\n",
    "        tanteo3.append(1)\n",
    "    else:\n",
    "        tanteo3.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49c671",
   "metadata": {},
   "source": [
    "### Rendimiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834963c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rendimiento=  0.1135\n"
     ]
    }
   ],
   "source": [
    "tanteo3_array=numpy.asarray(tanteo3)\n",
    "print(\"rendimiento= \",tanteo3_array.sum()/tanteo3_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066884d",
   "metadata": {},
   "source": [
    "### Probamos un ejemplo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fa17e020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15ed457f4f0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "numerito=plt.imread(\"numerito.png\")\n",
    "matplotlib.pyplot.imshow(numerito, cmap='Greys',\n",
    "interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2a1390b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=[]\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        if list(numerito[i][j]) == [0,0,0,1]:\n",
    "            aux.append(0)\n",
    "        else:\n",
    "            aux.append(1)\n",
    "numerito=aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "32245d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ca3b8d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La neurona 1 identifica un  8\n"
     ]
    }
   ],
   "source": [
    "salida1=n.prob(numerito)\n",
    "etiqueta1=numpy.argmax(salida1)\n",
    "print(\"La neurona 1 identifica un \",etiqueta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd9e0d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11064677],\n",
       "       [0.00708739],\n",
       "       [0.20811255],\n",
       "       [0.08842438],\n",
       "       [0.00375844],\n",
       "       [0.02582738],\n",
       "       [0.05144711],\n",
       "       [0.00689955],\n",
       "       [0.57417188],\n",
       "       [0.02069541]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6b69960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La neurona 2 identifica un  8\n"
     ]
    }
   ],
   "source": [
    "salida2=n2.prob(numerito)\n",
    "etiqueta2=numpy.argmax(salida2)\n",
    "print(\"La neurona 2 identifica un \",etiqueta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99367f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0433653 ],\n",
       "       [0.04143163],\n",
       "       [0.07737344],\n",
       "       [0.14051224],\n",
       "       [0.00764758],\n",
       "       [0.06004575],\n",
       "       [0.04990306],\n",
       "       [0.04323525],\n",
       "       [0.2519927 ],\n",
       "       [0.01361059]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf87416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La neurona 3 identifica un  1\n"
     ]
    }
   ],
   "source": [
    "salida3=n3.prob(numerito)\n",
    "etiqueta3=numpy.argmax(salida3)\n",
    "print(\"La neurona 3 identifica un \",etiqueta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8fbc5eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00557838],\n",
       "       [0.99531039],\n",
       "       [0.00346659],\n",
       "       [0.01763354],\n",
       "       [0.00837361],\n",
       "       [0.00933981],\n",
       "       [0.00487057],\n",
       "       [0.00730805],\n",
       "       [0.00591872],\n",
       "       [0.00576704]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da6e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
